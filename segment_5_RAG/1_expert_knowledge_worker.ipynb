{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdb853f",
   "metadata": {},
   "source": [
    "### Expert Knowledge Worker\n",
    "\n",
    "#### this is esseantially a question answering agent that is an expert knowledge worker\n",
    "\n",
    "#### to be used by comployees of `InsureLLM`, an insurance Tech Startup.\n",
    "\n",
    "#### the agent needs to be accurate and solution should be low cost.\n",
    "\n",
    "\n",
    "I will be using RAG(Retrieval Augmented Generation) to ensure the question/answering assistant has high accuract\n",
    "\n",
    "This is merely a brute-force type of RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ddae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import glob\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be155623",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b750279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d76d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "\n",
    "employees = glob.glob(\"knowledge-base/employees/*\")\n",
    "\n",
    "for employee in employees:\n",
    "    name = employee.split(' ')[-1][:-3]\n",
    "    doc =\"\"\n",
    "    with open(employee, \"r\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9112ec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Chen', 'Spencer', 'Tran', 'Blake', 'Lancaster', 'Thompson', 'Greene', 'Thomson', 'Trenton', 'Harper', 'Bishop', 'Carter'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72141223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HR Record\n",
      "\n",
      "# Alex Chen\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth:** March 15, 1990  \n",
      "- **Job Title:** Backend Software Engineer  \n",
      "- **Location:** San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\n",
      "- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company's growing platform.\n",
      "- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "- **2021:**  \n",
      "  - Achieved a 95% success rate in project delivery timelines.  \n",
      "  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \n",
      "\n",
      "- **2022:**  \n",
      "  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \n",
      "  - Conducted training sessions for junior developers, fostering knowledge sharing.  \n",
      "\n",
      "- **2023:**  \n",
      "  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \n",
      "  - Contributed to the company’s transition to a cloud-based infrastructure.  \n",
      "  - Received an overall performance rating of 4.8/5.\n",
      "\n",
      "## Compensation History\n",
      "- **2020:** Base Salary: $80,000  \n",
      "- **2021:** Base Salary Increase to $90,000; Received a performance bonus of $5,000.  \n",
      "- **2022:** Base Salary Increase to $100,000; Performance bonus of $7,500 due to exceptional project outcomes.  \n",
      "- **2023:** Base Salary Increase to $115,000; Performance bonus of $10,000 for leading pivotal projects.\n",
      "\n",
      "## Other HR Notes\n",
      "- Participates regularly in Insurellm's Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\n",
      "- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\n",
      "- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm's offerings.\n",
      "- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.  \n",
      "\n",
      "Alex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.\n"
     ]
    }
   ],
   "source": [
    "print(context['Chen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de02f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = glob.glob(\"knowledge-base/products/*\")\n",
    "\n",
    "for product in products:\n",
    "    name = product.split('/')[-1][:-3]\n",
    "    doc =\"\"\n",
    "    with open(product, \"r\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b06d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Chen', 'Spencer', 'Tran', 'Blake', 'Lancaster', 'Thompson', 'Greene', 'Thomson', 'Trenton', 'Harper', 'Bishop', 'Carter', 'Rellm', 'Markellm', 'Homellm', 'Carllm'])\n"
     ]
    }
   ],
   "source": [
    "print(context.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b729b2cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77076895",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert in answering accurate questions about Insurellm, the Insurance Tech Company.\n",
    "Give brief, accurate answers.\n",
    "If you dont know the answer, say so.\n",
    "Do not make anything up if you have not been provided with relevant context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53dff4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context=[]\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title.lower() in message.lower():\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34e15b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# HR Record\\n\\n# Alex Chen\\n\\n## Summary\\n- **Date of Birth:** March 15, 1990  \\n- **Job Title:** Backend Software Engineer  \\n- **Location:** San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\\n- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company\\'s growing platform.\\n- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\\n\\n## Annual Performance History\\n- **2020:**  \\n  - Completed onboarding successfully.  \\n  - Met expectations in delivering project milestones.  \\n  - Received positive feedback from the team leads.\\n\\n- **2021:**  \\n  - Achieved a 95% success rate in project delivery timelines.  \\n  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \\n\\n- **2022:**  \\n  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \\n  - Conducted training sessions for junior developers, fostering knowledge sharing.  \\n\\n- **2023:**  \\n  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \\n  - Contributed to the company’s transition to a cloud-based infrastructure.  \\n  - Received an overall performance rating of 4.8/5.\\n\\n## Compensation History\\n- **2020:** Base Salary: $80,000  \\n- **2021:** Base Salary Increase to $90,000; Received a performance bonus of $5,000.  \\n- **2022:** Base Salary Increase to $100,000; Performance bonus of $7,500 due to exceptional project outcomes.  \\n- **2023:** Base Salary Increase to $115,000; Performance bonus of $10,000 for leading pivotal projects.\\n\\n## Other HR Notes\\n- Participates regularly in Insurellm\\'s Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\\n- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\\n- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm\\'s offerings.\\n- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.  \\n\\nAlex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"chen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ea97b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if relevant_context:\n",
    "        message+=\"\\n\\n the following additional context might be relevant in answering this question: \\n\\n\"\n",
    "        for relevant in relevant_context:\n",
    "            message+=relevant+\"\\n\\n\"\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13e33714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Avery Lancaster\n",
      "\n",
      " the following additional context might be relevant in answering this question: \n",
      "\n",
      "# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \n",
      "\n",
      "- **2010 - 2013**: Business Analyst at Edge Analytics  \n",
      "  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2015**: **Exceeds Expectations**  \n",
      "  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \n",
      "\n",
      "- **2016**: **Meets Expectations**  \n",
      "  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \n",
      "\n",
      "- **2017**: **Developing**  \n",
      "  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \n",
      "\n",
      "- **2018**: **Exceeds Expectations**  \n",
      "  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \n",
      "\n",
      "- **2019**: **Meets Expectations**  \n",
      "  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \n",
      "\n",
      "- **2020**: **Below Expectations**  \n",
      "  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \n",
      "\n",
      "- **2021**: **Exceptional**  \n",
      "  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \n",
      "\n",
      "- **2022**: **Satisfactory**  \n",
      "  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \n",
      "\n",
      "- **2023**: **Exceeds Expectations**  \n",
      "  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\n",
      "\n",
      "## Compensation History\n",
      "- **2015**: $150,000 base salary + Significant equity stake  \n",
      "- **2016**: $160,000 base salary + Equity increase  \n",
      "- **2017**: $150,000 base salary + Decrease in bonus due to performance  \n",
      "- **2018**: $180,000 base salary + performance bonus of $30,000  \n",
      "- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \n",
      "- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \n",
      "- **2021**: $200,000 base salary + performance bonus of $50,000  \n",
      "- **2022**: $210,000 base salary + retention bonus  \n",
      "- **2023**: $225,000 base salary + $75,000 performance bonus  \n",
      "\n",
      "## Other HR Notes\n",
      "- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \n",
      "- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \n",
      "- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\n",
      "- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \n",
      "\n",
      "Avery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(add_context(\"Who is Avery Lancaster\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec3c8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT}]\n",
    "    for user, assistant in history:\n",
    "        messages.append({\"role\":\"user\", \"content\":user})\n",
    "        messages.append({\"role\":\"assistant\", \"content\":assistant})\n",
    "    message = add_context(message)\n",
    "    messages.append({\"role\":\"user\", \"content\":message})\n",
    "\n",
    "    stream = openai_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bee90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/protikmostafa/miniconda3/envs/llms/lib/python3.11/site-packages/gradio/chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
