{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f05297a0326401a8755585a748af025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed61d20406654e60b01931910df84e61",
              "IPY_MODEL_395629e97eef42b890a60c33349b4839",
              "IPY_MODEL_caec71c4a8834e4abbe1f9bf7dce1af2"
            ],
            "layout": "IPY_MODEL_01bd77f98c644daba376cb071f35e1c6"
          }
        },
        "ed61d20406654e60b01931910df84e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4bfa04764314b639cdd3e8c360b715e",
            "placeholder": "​",
            "style": "IPY_MODEL_cc858afb27c94cefa68c3e1f0717ef75",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "395629e97eef42b890a60c33349b4839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d6743ed153445db8fa18bcf26e7175",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c49f3b59f4214b5ea5b11c7874c35bfc",
            "value": 4
          }
        },
        "caec71c4a8834e4abbe1f9bf7dce1af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9ea387bc8d448ab5057e08bbaaad63",
            "placeholder": "​",
            "style": "IPY_MODEL_9750de780acf47ef93157468f030ffa4",
            "value": " 4/4 [00:11&lt;00:00,  2.52s/it]"
          }
        },
        "01bd77f98c644daba376cb071f35e1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bfa04764314b639cdd3e8c360b715e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc858afb27c94cefa68c3e1f0717ef75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3d6743ed153445db8fa18bcf26e7175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49f3b59f4214b5ea5b11c7874c35bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb9ea387bc8d448ab5057e08bbaaad63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9750de780acf47ef93157468f030ffa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Meeting Assistant UI\n",
        "\n",
        "The task here is to:\n",
        "1. Take audio input from a meeting. Upload it to gradio interface.\n",
        "2. generate minutes\n",
        "3. generate actions from it.\n",
        "\n",
        "I will use a frontier model to convert the audio into text <br>\n",
        "I will use an open-source model to generate minutes<br>\n",
        "Stream back the result as actionable items as a form of markdown.\n"
      ],
      "metadata": {
        "id": "l3wnqglW0XIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## installation\n",
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOp_oyWL0sal",
        "outputId": "2684352a-b925-4233-cead-64e2355875bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## imports\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import display, Markdown, update_display\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import torch\n",
        "import gradio as gr\n",
        "import gc"
      ],
      "metadata": {
        "id": "Q3CLaVx20v3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## configuration\n",
        "AUDIO_MODEL = \"whisper-1\"\n",
        "LLAMA = \"meta-llama/Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "m47SST-n1OuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## log in to hugging face\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(hf_token,add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "mEx8qRdz1XeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## openai configuration\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "mLhCD6X01kN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## transcription function\n",
        "def transcribe_audio(file_obj):\n",
        "  with open(file_obj, \"rb\") as audiofile:\n",
        "    transcription = openai_client.audio.transcriptions.create(\n",
        "        model=AUDIO_MODEL,\n",
        "        file=audiofile,\n",
        "        response_format=\"text\"\n",
        "    )\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "yDvKVJie14cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "PqnxTVds4aPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLAMA,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=None,\n",
        "    trust_remote_code=True\n",
        ").to(\"cuda\")\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "4f05297a0326401a8755585a748af025",
            "ed61d20406654e60b01931910df84e61",
            "395629e97eef42b890a60c33349b4839",
            "caec71c4a8834e4abbe1f9bf7dce1af2",
            "01bd77f98c644daba376cb071f35e1c6",
            "b4bfa04764314b639cdd3e8c360b715e",
            "cc858afb27c94cefa68c3e1f0717ef75",
            "d3d6743ed153445db8fa18bcf26e7175",
            "c49f3b59f4214b5ea5b11c7874c35bfc",
            "cb9ea387bc8d448ab5057e08bbaaad63",
            "9750de780acf47ef93157468f030ffa4"
          ]
        },
        "id": "PHnQ0Z3qAuWH",
        "outputId": "6a751a65-969b-40de-db40-40c625bf8622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f05297a0326401a8755585a748af025"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## function to generate meeting minutes\n",
        "def generate_minutes(transcript):\n",
        "  SYSTEM_PROMPT=\"\"\"\n",
        "  You are a very helpful assistant that can produce meeting minutes from transcripts.\n",
        "  You provide a summary; key discussion point; takeaways and action items with owners.\n",
        "  You provide the output in Markdown format.\n",
        "  \"\"\"\n",
        "  USER_PROMPT=f\"\"\"\n",
        "  Please write meeting minutes in Markdown, including summaries, key discussions, takeaways, and action items.\n",
        "  If you find any name, please replace the name with an adjective and another noun like experiment names.\n",
        "  Below is the transcript of the meeting:\n",
        "  {transcript}\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "      {\"role\": \"user\", \"content\": USER_PROMPT}\n",
        "  ]\n",
        "  print(messages)\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(\"cuda\")\n",
        "\n",
        "  # generate output\n",
        "  outputs = model.generate(\n",
        "      inputs,\n",
        "      max_new_tokens=2000,\n",
        "      do_sample=True,\n",
        "      temperature=0.7\n",
        "  )\n",
        "\n",
        "  new_tokens=outputs[0, inputs.shape[-1]:] # removing the echo from solution\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "  print(\"last\")\n",
        "  return response"
      ],
      "metadata": {
        "id": "LPNExQaB38X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pipeline wrapper\n",
        "def meeting_assistant(file_obj):\n",
        "  transcript = transcribe_audio(file_obj)\n",
        "  minutes = generate_minutes(transcript)\n",
        "  return minutes"
      ],
      "metadata": {
        "id": "qvuWjI1y5UeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"## Meeting Minutes Assistant\")\n",
        "\n",
        "  with gr.Row():\n",
        "    audio_input = gr.Audio(sources=[\"upload\"], type=\"filepath\", label=\"upload meeting audio here\")\n",
        "\n",
        "  output = gr.Markdown()\n",
        "\n",
        "  btn = gr.Button(\"Generate Summary\")\n",
        "  btn.click(meeting_assistant, inputs=audio_input, outputs=output)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "4bxTcpqS5zOL",
        "outputId": "57a674a2-22b4-46f0-d3d4-a3b323a89e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a51f2720545b84b408.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a51f2720545b84b408.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': '\\n  You are a very helpful assistant that can produce meeting minutes from transcripts.\\n  You provide a summary; key discussion point; takeaways and action items with owners.\\n  You provide the output in Markdown format.\\n  '}, {'role': 'user', 'content': \"\\n  Please write meeting minutes in Markdown, including summaries, key discussions, takeaways, and action items.\\n  If you find any name, please replace the name with an adjective and another noun like experiment names.\\n  Below is the transcript of the meeting:\\n  I'm guessing in the session here today, is there anyone who's not had a phone screening call yet? Everyone's had a phone screening call, everyone's got, Srishti hasn't had a phone screening call yet. Anyone else who hasn't yet had a phone screening interview? No. All right. Just as revision for everyone else, right? So, what are the things you need to know about in a phone screening interview? Phone screening interviews usually are the first step, right? So, whenever you submit your online application to a recruitment company or to many bigger tier 1 companies, the first thing they'll do is that they either have a recruiter or a talent acquisition professional who would give you a call, right, to validate the information that you've mentioned in your resume. These calls can be as quick as 5 minutes, they can go for as long as 30 minutes, right? This is one thing that you need to know about, that in phone screening interviews, right, you can't see the other person. So, all that you're trying to do is that you're trying to pick up all your communication as well, all the cues there are non-verbal. So, at this point in time, what I advise is that keep your answers concise and keep them to the point, right? That is one of the first things that we want to do. In one-on-one digital interviews, when you can see someone on Teams, when you can see someone in person, right, there's a lot more wiggle room because you can see that, hey, my answer is going on for too long and the other person is getting bored or you can see the interviewer, you can see that they want you to wrap up that answer or you can see them confused, right? In these interviews, in our phone screening interviews, you can't see any of those. So, again, a good rule of thumb there is just to be concise with your answers. The other thing that you need to know about phone screening interviews is that for all of you who are targeting technical roles, right, the recruiter, the talent acquisition professional, in 90% of the cases we will be speaking with, would not be a technical person. So, your answers, there is no need for you to get into too much technicality, there's no need to get into a lot of depth about how you did coding, right? All you need to do is that you need to use phrases, you need to use terms from the position description to tell the interviewer that you've got experience with that. Which is why, with everything, what they are trying to do is they are trying to verify the information that you've mentioned on your application in your resume. So, hey, Nilangi, in your resume you've mentioned or we saw that you worked in XYZ company as a front-end developer, right, can you tell me a bit more about that role? These are the sorts of questions they are asking because they want to validate that information. After the phone screening interview, what the recruiter does is, just like they've called you, they've called five, six other people, they've taken down notes, right, they'll go through those notes, they'll probably have a word with the hiring manager about those notes and then they shortlist two or three different people for their one-on-one interview with the hiring manager. That is the most important thing that is going on in a phone screening interview, which is why, again, in a phone screening interview, your best friend is the position description, right, and what we want to make sure is that, just like when you're writing the selection criteria, right, that there are six things given in the position description, we want to make sure that we've covered most of them in our responses in phone screening interviews because we do that well and we almost guarantee an in-person interview or a digital interview with the hiring manager. Any questions yet about phone screenings? I was wondering that, in a way, it's just us speaking out a cover letter. Can we say that? Because we're ultimately scanning through the position description and specific questions when they're asking, okay, what do you bring in this company or etc. So, it's like that. Yes, in a certain light, right, it can be looked at that way. The one distinguishing factor that I make between these two things or even between in-person interviews, digital interviews, which are with a hiring manager and interviews like these with a talent acquisition professional, right, there's a difference between breadth and depth, right. So, in a phone screening interview, you always, our aim pretty much is to cover breadth as per the position description, right. So, if I can see in the position description that there are things around data visualization, data modeling, data anchoring, data sampling, data migration, I want to make sure that in my responses or in a phone screening interview, I'm mentioning those things like I'm covering the breadth of it, but I'm not covering the depth of it in terms of how did I make that happen. Whereas in an interview with a hiring manager, right, our priority always is to cover the depth rather than the breadth. So, if I'm in a room with the hiring manager, instead of telling the hiring manager that, hey, I've done data modeling, I've done data analysis, visualization, right, I've done all these things, I want to focus only on one thing, that, hey, I've done data migration. On this particular project, I did data migration, and now I want to give her all the details about the data migration that I did. What was the role where I did data migration, right, in what capacity did I do that in, what was the data set I was working with, what were the tools that I was using, because the hiring manager would understand that, right, they are more interested in the depth of it, whereas with the talent acquisition professional recruiter, again, depending on how advanced that company is, many, many cases, they would not be able to understand the two technically specific details that you share. So, that's how I want you to think about this. Phone screening interviews, breadth, hiring manager, in-person calls, right, that is where we cover the depth with each and every possible detail about that particular scenario or response. Again, in terms of how to prep up for this, right, if there is an email that you have received, which in most cases you will not receive, right, but if there's an email you've received about the phone screening call, you want to make sure that you are absolutely clear about the call time, you're absolutely clear about who would be calling, what is the expected duration of it, and if there are any specific preparation instructions there, right. At every point in time, right, you need to know who is it that you're talking to, because your answers vary a lot with that. Our communication style, this is what I want you to think about, our communication style is always based on the person, right, so the way I explain to a marketing mentee is not how I explain to a data analytics mentee, the way I speak with my dad is not how I speak with my son, even though I don't have a son, or I don't have a kid, but just as an example, right, the way you talk to your grandfather is not the same way you talk to your father, that's a better example actually, so that's how I want you to think about it. So even if the way you're talking to a hiring manager, a senior director of data analytics at a company, a senior marketing manager, senior finance manager, is not how you speak with, if it is a recruiter who's having this phone screening call with, right, in terms of the details, so just have that in mind. Apart from that, some very basic instructions around how to prepare for it, like you always need to know a few questions for the phone screening interview, which will come further down the line, right, but one of those questions is tell us more about yourself, right, then there will be a question about your previous role, are you working in that role currently, there might be a question about why do you want to leave that role, why are you looking for a role right now, there would be a question about what are your salary expectations, right, what is your visa status, and apart from that, there might be a few behavioral questions. When you give two to three phone screening interviews, right, you would already have an idea about what sort of interview questions you're asked, and in most phone screening interviews, those questions remain the same. As with everything, after every phone screening interview, write down a list of those questions that you were asked. If you did have a problem answering any question, let Glenn and I know, so that we are in a position to help you. Just like how just like when we started the session, Harsha mentioned, right, that there are two questions, I've got a problem answering. That is great. That is fantastic. That is what we are here for. Right. But from your end, you need to be you need to be making these decisions. And you need to be making this analysis consciously. But hey, in this interview, I was asked this question, and I was stumped. I didn't know how to respond. I didn't know what to respond. And I need to know this. So let me ask Glenn about it. Right? Have this in your head. Now, unexpected phone interviews, which is the worst part of interviewing, that any Tom, Dick and Harry can call you at any point in time, and they'll ask you questions about the job. Right? So at any point in time, you can get a call from any recruiter. The first thing that I want you to understand here is that if it is not so I get a call from a recruiter, and I'm watching Netflix, I'm on my laptop, right, I'm out with my friends, or I'm not doing anything. Right? Let's just say I wasn't prepared for it. And you get a call. The first thing I want you to do is to take that call and tell the recruiter, take down their names that Hey, um, can I get once again, where are you calling from? And can I catch your name? Once again, I didn't catch it. They'll tell you their name again, they'll tell you their company again. Note it down. Right? Tell them that James right now I'm annoyed I'm at a night I'm at a noisy place. Is it fine if I can give you a call back within 10 minutes? Right? It's absolutely to ask them that if it is a question if it is an interview where you're just not in the right frame of mind, or you were not expecting that call. Tell them that you've got this thing, right? Tell them that you're in a noisy place. The other thing that I used to do when I was applying for jobs, right? So from my end, I wouldn't take calls from unknown numbers. I knew that any call that I'm getting from an unknown number, there is a high chance that it is called it is a call from a recruiter. And I just didn't want to take that call. I would rather that that call goes into my voicemail. In that voicemail, that recruiter would tell their name, and the name of the company that would give me the chance to go to my seek profile, see what jobs did I apply for, go to my LinkedIn profile, see what job did I apply for, and then give them a call back within again, 10 to 15 minutes, 15 to 20 minutes, very, very quickly to discuss about that opportunity. Do any of these, right, but just make sure that you're prepared for the conversation. I would rather that you let it letting the call go to a voicemail, or telling the recruiter that you are in a busy place right now and you can't take the call and can you give them a call in 10 minutes is 1000 times better than answering the call interview call unprepared, where they tell you, and you don't even know when the hell did I apply for this job? What role are we talking about? I can't even fathom what does that company do? And it's all downhill from that. Any questions about this particular approach, this particular strategy, this person, this particular tactic? Nope. Thanks, someone unmute someone unmuted them. So I thought that there was a question. Never mind. We will go further with one on one interviews, digital in person. Right? Let me get your back on my screen. Here we are. One on one interviews digital in person. This is where firstly, the most important aspect of any interview, right, is always your first impression. There have been studies after studies, which have shown that actually one third of the interviewers finalize their hiring decision in the first 90 seconds of an interview, right? Where they know whether they're going to hire you, or they know that this is someone who would not be hired. Right, the decision has already been made in the first 90 seconds of an interview. So that is the first part that I want you to know that the way you start an interview, the first 90 seconds of an interview, are just very, very important. Right, then we get the other part about it, which is how do you establish that in the first 90 seconds? How do you establish that? So there's a question here about small talk, right, which would help you create that impression. And then there's an aspect of the interview itself, right? That would help you create that impression. And then there's an aspect there about the first question that you're asked, which is, tell us about yourself. The two most important aspects when it comes to creating a killer impression. Small talk, which is where we got to with Xavier's question, right, so small talk to kickstart an interview. All interviews in Australia will start off with small talk, which would be how you house your take on, right? That is what every interview will start off with. Now, here, when you're asked this question, in an in person interview, there are choices, right? One choice that we've got is that you can just say, I'm good. How are you doing? Right? And there's nothing wrong about it at all. Like that is how most people would answer this question. But again, there's nothing great about it. It is just a very, very risk averse way of getting past it that Hey, how are you doing? I'm well. How are you? I'm doing well as well. Okay, tell me more about yourself. That is how 90% of the interviews would start. Let's think about how can we break that script? Right? So if someone asks you, hey, how are you doing? Or how? Thanks for coming to this interview. How's the day been so far? And you tell them something, and you answer it like this, that it's been productive. So far, I started off by reading this article, how this Australian startup is electrifying 3d printing. Pretty amazing how they're developing 3d printers at the size of a coffee table. Right? How about you? How's your day going? Giving them something extra in the conversation that keeps that small talk going, right? More than anything else. Now, this could be about your interest as well. This could be about your particular field as well. But hey, just got off taking a lecture at a university or tutoring students again, something a bit more specific than I'm doing good. How about you? This is a tricky aspect in here. Right? Because again, that is one of the ways through which we just get more traction. Yeah. So, Xavier, does that answer your question about small talks? Yeah, a little, but I'm still trying to find out what's a good topic to talk about. Sorry, can you repeat the last bit? Can you hear me? Yes, I can hear you. Trying to figure out what I should talk about that's not too, that's not straying too away from. Yeah, just in general. Okay, so here it would. So with this particular aspect, like I think the topics need to be what we need to have thought about, right? Some topics to think about, talk about something that is going on in the news about your industry, right? That is always a great one. A particular course or anything technical that you are doing, right? That is again, a great one as well in terms of you learning an item, right? In terms of you, let's say learning a programming language or you doing a project. The third part of it could be anything that you're doing in your part-time casual volunteering capacity. That is how I would think about it. Okay, yeah, that makes sense. I guess something technical will be better than in this case. Like let's say I'm starting a new project or like just reading up on some article on some programming language or yeah, something like that. Yes, but make sure like it is make sure that you are prepared to have a conversation about it. Right? So if that person asks you, okay, sounds fantastic. What was that article? At that point in time, we cannot go blank about it. At that point in time, like it, yeah, it cannot be a made up thing that we're talking about that we're talking about just for the sake of talking about it. Because there can be, it needs to be a topic, it needs to be something that you can have a 15, 20 minute conversation around. That's how I would put it. Okay, yep. Okay, perfect. So that would be about the small talk, right? Then we get down to the main question, tell us about yourself. Now, everyone is asked this question, right? I've written a lot of text in here about how to answer this question. But what I want us to think about is that there are a few very, very important things that we just that we need to get right. The first thing here with tell us about yourself question, right, is that your first statement needs to be a value driven statement, where you define yourself as the role title that they're looking for. And you talk about your experience in what are the things that they want they want that are mentioned in the job description. Again, position description, like we do in our resume reviews, right? 90% of it is even in your resume, what is the position description asking me of asking me to do and that is what I need to mention. That's all right. So in this case, if I know that the most the position description and asking me is to analyze and visualize data, right? I will say that I'm a data analyst with these many years of experience in analyzing and visualizing data. Right? If it is about a marketing analytics position, where they've mentioned about Google Analytics and stuff, right, I need to take those same words and I need to mention them in here right away. The recruiter, the hiring manager needs to know that what I am looking for for the prime reason that I want to hire someone, and the prime reason why we are hiring, that is the exact experience that this person has got. I'm looking for a data analyst, hey, there's a data analyst with two years of experience in doing the same things that I want. We are looking for a front end developer, there is a front end developer who's got experience with the same things that we want. This is what you want to mention. The first sentence, very, very important. Second part of it, you want to tell them where is it that you're currently working? Right? If you're currently working somewhere, or if you're not currently working somewhere, but you've previously done an internship somewhere, where you worked in that exact same capacity, you want to mention that, right? Previously, again, if you're doing it currently, it's currently I'm working with the energy storage research group. If I did that previously, previously, I worked with the energy storage research group as a front end developer, where I again, in one sentence, what did you do with them? In this part, again, you can include the tech tools, you can use the programming languages that we use as part of that. From there on, you go to talk about your master's or your bachelor's degree from a particular university. Again, expand on the capstone projects that you did, right? Talk about your experience a bit more when you're talking about that. And then the last point that we want to wrap it up with is why are you excited about working for that organization? That is what we want. Any, any questions about this one? This is the most frequently asked question, which you're asked in every phone screening, which you're asked in every, right? So more than anything, I think it is important for us to get this one question, right? Any questions about this? No. All right. Next, we jump on to behavioral interview questions. Right? These are the questions. Again, you'll be asked these questions in every, every interview, right? And these questions, the reason why you're firstly, what are these questions? These are the questions where you are asked, tell us about a time where you encountered a difficult problem, encountered a difficult stakeholder, encountered where you delivered exceptional customer service, where a project was not going according to the timeline, and you delivered it in a way that it went as per the timeline. These are the things that we are wanting to get right as part of this. Right? So these are the questions you're asked in a behavioral interview. The reason why they've got behavioral interview questions is because they want to make sure that the experience that you've got in your resume, right? You're not in very simple terms, you're not bullshitting in there. Which is why they're asking you specific questions. But hey, Srishti, you've mentioned that this is a role that you did, or this is an internship that you did. Can you tell us about a time where you did this as part of that internship? Right? Can you tell me about a time where you saw the specific problem? Now, here, we want to get into as much depth as possible. Right? We want to tell them about each and everything about the problem. And how did we solve it? Right? This is the only way you would clear these questions, they need to have as much information about it as possible. What we'd like to do is obviously, almost everyone in here, right has got some sort of an experience with behavioral questions, either as part of their interview prep, or many of you have had interviews previously, where you were asked these questions. So what I would have us do right again, and this is an exercise we'll do next time around, because I think we're just lacking the time. But I would like to explain to you how to answer these questions. Mostly behavioral questions. There are six types of teams that you're asked about it, right? Now, Rujda, tell me about a time when you were working in a team, right? And what was the project that you delivered? Mustafa, tell me about a time where you delivered exceptional customer service, right? Utkarsh, tell me about a time where you dealt with failure? Glenn, tell me about a time where you encountered a difficult stakeholder or customer on a project? What did you do to get past it? Srishti, tell me about the time as to when there were multiple competing priorities on a project? And how did you prioritize that? Right? These are mostly the six teams where you're asked behavioral questions. And in each of these things. Now, the format that we've got is called CARS, which is Challenge Action Result Summary. I don't care, you can call this STAR as well, because essentially, it is the same thing. There is no difference between CARS and STAR. It is the exact same thing. The only thing that we need to know about here is that there needs to be enough detail in your answers. Right? The first thing here is that we need to tell them about the specific instance. During my internship as a graduate consultant at 180 Degrees Consulting, I was assigned to a project aimed at implementing a new software system for the client. One of the key stakeholders involved was a senior executive who was known for being resistant to change and frequently challenged our decisions. This created a challenging dynamic and threatened the progress of the team. Right? This is the challenge. This is the situation and the task at hand. Now we come to the point which is your action. This is where 90% of your effort needs to be. What did you specifically do to resolve this problem? I requested a one-on-one meeting with the executive to better understand their perspective and gather insights into their reservations. During the meeting, I actively listened to their concerns, acknowledged their expertise, and explained the project's objectives, benefits, addressed my misconceptions. After that, I also offered to arrange demonstrations to address specific concerns. This is how Utkarsh solved the problem and this is what the interviewer wants to know. Right? This is how we respond to any behavioral question for that matter. Right? Any behavioral question would be answered very similarly. It is the same format that we are following. It is the same approach that we're taking in any of these. Right? Again, I've got another example about this approach as well, but that's exactly what we're trying to do as part of this. Just noting the time, guys, I don't think we'll be able to do this quite a bit that I want to cover after this as well. I think we'd have to, just because of how important this topic is, I would rather break this over two sessions. I think we'd have to do it in two sessions. I think we'd have to do it in two sessions. I think we'd have to do it in two sessions. I think we'd have to do it in two sessions. I think we'd have to do it in two sessions. I think we'd have to do it in two sessions. We'll share the slide deck in the community chat as well because this has got the sample responses. So if you want to go through these responses, if you want to write down answers for your responses and you want Glenn and I to review it as well, do that. Send it our way for review. We're more than happy to review it. We're more than happy to provide you with that feedback around, you know, how can we improve these answers. Right. So we've got this interview session. I think we'll wrap up this session now. We'll have another interview prep session, which is where we'll do a mock exercise to go through how is it that we are responding to certain questions. What is it better that we can do at that point in time, right? So there would be another session around interview prep that we'd be scheduling when we take that call. But in the meanwhile, if you've got any questions about this, please feel free to reach out to me. I'll be happy to answer any questions that you may have.\\n\\n  \"}]\n",
            "last\n"
          ]
        }
      ]
    }
  ]
}